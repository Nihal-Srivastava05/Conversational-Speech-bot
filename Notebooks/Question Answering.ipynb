{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb4074e",
   "metadata": {},
   "source": [
    "## Question Answering - Transformer Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9e85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e6196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/electra-base-squad2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc6f34bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cefec82a42e4e38bc0ec0e0d28b99b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/635 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18f9266fae343da96af59319235fc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4714abcade4a8b802d7d768891dd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d01d3494a343fe87f5cd8421952052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1a58e9a91945edb28e4a7304382e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_answer = pipeline(\"question-answering\", model=\"deepset/electra-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86060382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../Dataset/final_paraphrased_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f01c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Bus starts from Rwanda at 02:51 AM and goe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The bus arrives at Switzerland by 8:13 AM afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Bus starts from United Kingdom at 09:58 AM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The bus arrives at United States Minor Outlyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Bus starts from United Arab Emirates at 06...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  The Bus starts from Rwanda at 02:51 AM and goe...\n",
       "1  The bus arrives at Switzerland by 8:13 AM afte...\n",
       "2  The Bus starts from United Kingdom at 09:58 AM...\n",
       "3  The bus arrives at United States Minor Outlyin...\n",
       "4  The Bus starts from United Arab Emirates at 06..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba53bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "for sent in df.iterrows():\n",
    "    context += sent[1]['text'] + \". \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "76dee705",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/context.txt', 'w') as f:\n",
    "    f.write(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38bb7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_input = {\n",
    "    'question': 'Where does the bus from Rwanda reach to if it starts from there at 02:51 AM',\n",
    "    'context': context\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd70c3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:703: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:297: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9962866306304932, 'start': 51, 'end': 62, 'answer': 'Switzerland'}\n"
     ]
    }
   ],
   "source": [
    "res1 = question_answer(QA_input)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43a6e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9991130232810974, 'start': 69522, 'end': 69530, 'answer': '02:45 PM'}\n"
     ]
    }
   ],
   "source": [
    "QA_input = {\n",
    "    'question': 'At what time does the bus which reaches south georgia from mexico leave at',\n",
    "    'context': context,\n",
    "}\n",
    "res1 = nlp(QA_input)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476384e1",
   "metadata": {},
   "source": [
    "This takes a lot of time as our context is very big. We can extract keywords and reduce this context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a67dbf",
   "metadata": {},
   "source": [
    "## Performing NER and reducing context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c776ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"Where does the bus from Rwanda reach to if it starts from there at 02:51 AM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "613f57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f47f3370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9403c6343704178865931d2c0bdd852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db14ad946c854c6f972f7a1cfae3aa9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a288637a8fe64cd2ac296332c83c15d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1483d5349cb64aada1f45877f60afb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2399c29eda8948e3947d748568dcf78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d17de1dfb84ba49d814d3cf5e8f858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad99e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d29595c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-LOC',\n",
       "  'score': 0.99984074,\n",
       "  'index': 6,\n",
       "  'word': 'Rwanda',\n",
       "  'start': 24,\n",
       "  'end': 30}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results = ner(t)\n",
    "ner_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a2744",
   "metadata": {},
   "source": [
    "## Keyword Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4163159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b165da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b81b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n, nr_candidates):\n",
    "    # Calculate distances and extract keywords\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, \n",
    "                                            candidate_embeddings)\n",
    "\n",
    "    # Get top_n words as candidates based on cosine similarity\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # Calculate the combination of words that are the least similar to each other\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    if(candidate):  \n",
    "        return [words_vals[idx] for idx in candidate]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a0dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmr(doc_embedding, word_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # Extract similarity within words, and between words and the document\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
    "    word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    # Initialize candidates and already choose best keyword/keyphras\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        # Extract similarities within candidates and\n",
    "        # between candidates and selected keywords/phrases\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # Calculate MMR\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        if(mmr.size > 0):\n",
    "            mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "            # Update keywords & candidates\n",
    "            keywords_idx.append(mmr_idx)\n",
    "            candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0b8c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_keyBert(sentences, model_name='distilbert-base-nli-mean-tokens', n_gram_range=(1, 2), stop_words=\"english\", top_n=10, diversification=None, nr_candidates=15, diversity=0.5):\n",
    "    #Get candidate phrases\n",
    "    count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([sentences])\n",
    "    candidates = count.get_feature_names_out()\n",
    "    \n",
    "    #Load Model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    doc_embedding = model.encode([sentences])\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "    \n",
    "    #Calculate distance between embedding to find similarty\n",
    "    if(diversification == None):\n",
    "        distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "        keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "    elif(diversification == 'max_sum_sim'):\n",
    "        keywords = max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=top_n, nr_candidates=nr_candidates)\n",
    "    elif(diversification == 'mmr'):\n",
    "        keywords = mmr(doc_embedding, candidate_embeddings, candidates, top_n=top_n, diversity=diversity)\n",
    "    \n",
    "    return list(set(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a8d6f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rwanda', 'bus', '02']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keywords_keyBert(t, model_name='all-MiniLM-L6-v2', n_gram_range=(1, 1), diversification='mmr', top_n=3, diversity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b918d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_context = set()\n",
    "for keyword in ['02', 'rwanda']:\n",
    "    for sent in context.split('. '):\n",
    "        if keyword in sent.lower():\n",
    "            possible_context.add(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "181bfe63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "28c2f304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1717"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "839a01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short_context(question, context):\n",
    "    keywords = get_keywords_keyBert(question, model_name='all-MiniLM-L6-v2', n_gram_range=(1, 1), diversification='mmr', top_n=3, diversity=0.8)\n",
    "    possible_context = set()\n",
    "    for keyword in keywords:\n",
    "        for sent in context.split('. '):\n",
    "            if keyword in sent.lower():\n",
    "                possible_context.add(sent)\n",
    "    possible_context = list(possible_context)\n",
    "    possible_context = '. '.join(possible_context)\n",
    "    \n",
    "    return possible_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8cedbc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "quest1 = 'Where does the bus from Rwanda reach to if it starts from there at 02:51 AM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b455f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_context1 = get_short_context(quest1, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2849f4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:703: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:297: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9983903765678406, 'start': 31592, 'end': 31603, 'answer': 'Switzerland'}\n"
     ]
    }
   ],
   "source": [
    "QA_input = {\n",
    "    'question': 'Where does the bus from Rwanda reach to if it starts from there at 02:51 AM',\n",
    "    'context': short_context1\n",
    "}\n",
    "\n",
    "res = question_answer(QA_input)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "66870742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(question, context):\n",
    "    short_context = get_short_context(question, context)\n",
    "    qa_input = {\n",
    "        'question': question,\n",
    "        'context': short_context\n",
    "    }\n",
    "    res = question_answer(qa_input)\n",
    "    \n",
    "    final_answers = set()\n",
    "    for r in res:\n",
    "        if(r['score'] > 0.99):\n",
    "            final_answers.add(r['answer'])\n",
    "        \n",
    "    return list(final_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2eb96",
   "metadata": {},
   "source": [
    "## Top k sentences as answers based on score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "25cf9b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:189: UserWarning: topk parameter is deprecated, use top_k instead\n",
      "  warnings.warn(\"topk parameter is deprecated, use top_k instead\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "question_answer2 = pipeline(\"question-answering\", model=\"deepset/electra-base-squad2\", topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6054c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quest2 = \"Where does the bus reach as 4:30 A.M.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0fe541c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:703: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:297: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9983903765678406,\n",
       "  'start': 31592,\n",
       "  'end': 31603,\n",
       "  'answer': 'Switzerland'},\n",
       " {'score': 0.9956767559051514,\n",
       "  'start': 77798,\n",
       "  'end': 77809,\n",
       "  'answer': 'Switzerland'},\n",
       " {'score': 0.991287887096405,\n",
       "  'start': 61969,\n",
       "  'end': 61977,\n",
       "  'answer': 'Kiribati'},\n",
       " {'score': 0.9760979413986206,\n",
       "  'start': 36098,\n",
       "  'end': 36103,\n",
       "  'answer': 'Kenya'},\n",
       " {'score': 0.9745321869850159,\n",
       "  'start': 117837,\n",
       "  'end': 117842,\n",
       "  'answer': 'Kenya'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answers(question_answer2, quest2, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "378741f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quest3 = \"At what time does the bus which reache Finland from United Kingdom\"\n",
    "t = get_answers(pipeline, quest3, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b215fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_context3 = get_short_context(quest3, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "33f0124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:703: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:297: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9998883605003357, 'start': 69999, 'end': 70006, 'answer': '8:26 PM'}, {'score': 0.9998598694801331, 'start': 114148, 'end': 114155, 'answer': '4:03 AM'}, {'score': 0.9993850588798523, 'start': 114148, 'end': 114155, 'answer': '4:03 AM'}, {'score': 0.9993388056755066, 'start': 65663, 'end': 65670, 'answer': '3:22 AM'}, {'score': 0.9992659687995911, 'start': 54771, 'end': 54778, 'answer': '5:27 AM'}]\n"
     ]
    }
   ],
   "source": [
    "qa_input = {\n",
    "    'question': quest3,\n",
    "    'context': short_context3\n",
    "}\n",
    "\n",
    "res = question_answer2(qa_input)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbdbfb2",
   "metadata": {},
   "source": [
    "## Final Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ff47e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(question, context):\n",
    "    short_context = get_short_context(question, context)\n",
    "    qa_input = {\n",
    "        'question': question,\n",
    "        'context': context\n",
    "    }\n",
    "    res = question_answer2(qa_input)\n",
    "    print(res)\n",
    "    final_answers = set()\n",
    "    for r in res:\n",
    "        if(r['score'] > 0.99):\n",
    "            final_answers.add(r['answer'])\n",
    "        \n",
    "    answers = list(final_answers)\n",
    "    if(len(answers) == 0):\n",
    "        return 'No buses available for this route and time'\n",
    "    else:\n",
    "        return ', '.join(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ba5d005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:703: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "C:\\Users\\nihal\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:297: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.026512378826737404, 'start': 1459, 'end': 1477, 'answer': 'starts from Rwanda'}, {'score': 0.02013932168483734, 'start': 1451, 'end': 1477, 'answer': 'The Bus starts from Rwanda'}, {'score': 0.013502407819032669, 'start': 1471, 'end': 1477, 'answer': 'Rwanda'}, {'score': 0.005046140402555466, 'start': 15403, 'end': 15459, 'answer': 'The bus arrives at Montenegro by 3:07 PM after departing'}, {'score': 0.0028550198767334223, 'start': 15436, 'end': 15459, 'answer': '3:07 PM after departing'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"All busses that Bus starts at 09:31 PM and goes to Angola\"\n",
    "get_answers(q, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1edc5285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kiribati', 'Switzerland']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = list(final_answers)\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b7f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
